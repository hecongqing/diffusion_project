#!/usr/bin/env python3
"""
å¯è§†åŒ–å·¥å…·å‡½æ•°
============

è¿™ä¸ªæ¨¡å—æä¾›å„ç§å¯è§†åŒ–åŠŸèƒ½ï¼š
1. è®­ç»ƒæ›²çº¿ç»˜åˆ¶
2. ç”Ÿæˆæ ·æœ¬ç½‘æ ¼å±•ç¤º
3. æ‰©æ•£è¿‡ç¨‹å¯è§†åŒ–
4. æ³¨æ„åŠ›çƒ­å›¾å¯è§†åŒ–

ä½œè€…: Diffusionæ•™ç¨‹å›¢é˜Ÿ
æ—¥æœŸ: 2024å¹´
"""

import os
import torch
import torch.nn.functional as F
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
from matplotlib.animation import FuncAnimation
import seaborn as sns
from PIL import Image, ImageDraw, ImageFont
from torchvision.utils import make_grid, save_image
from typing import List, Optional, Tuple, Union
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'SimHei', 'Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False

def plot_training_curves(
    train_losses: List[float],
    val_losses: List[float],
    save_path: str,
    title: str = "è®­ç»ƒæ›²çº¿",
    show_best: bool = True
) -> None:
    """
    ç»˜åˆ¶è®­ç»ƒå’ŒéªŒè¯æŸå¤±æ›²çº¿
    
    å‚æ•°:
        train_losses: è®­ç»ƒæŸå¤±åˆ—è¡¨
        val_losses: éªŒè¯æŸå¤±åˆ—è¡¨
        save_path: ä¿å­˜è·¯å¾„ï¼ˆç›®å½•ï¼‰
        title: å›¾è¡¨æ ‡é¢˜
        show_best: æ˜¯å¦æ ‡è®°æœ€ä½³ç‚¹
    """
    plt.figure(figsize=(12, 8))
    
    epochs = range(1, len(train_losses) + 1)
    
    # ç»˜åˆ¶è®­ç»ƒå’ŒéªŒè¯æ›²çº¿
    plt.subplot(2, 2, 1)
    plt.plot(epochs, train_losses, 'b-', label='è®­ç»ƒæŸå¤±', linewidth=2)
    plt.plot(epochs, val_losses, 'r-', label='éªŒè¯æŸå¤±', linewidth=2)
    
    if show_best and val_losses:
        best_epoch = np.argmin(val_losses) + 1
        best_loss = min(val_losses)
        plt.scatter(best_epoch, best_loss, color='red', s=100, zorder=5)
        plt.annotate(f'æœ€ä½³: Epoch {best_epoch}\nLoss: {best_loss:.4f}',
                    xy=(best_epoch, best_loss),
                    xytext=(best_epoch + len(epochs) * 0.1, best_loss + max(val_losses) * 0.1),
                    arrowprops=dict(arrowstyle='->', color='red'),
                    fontsize=10, color='red')
    
    plt.xlabel('Epoch')
    plt.ylabel('æŸå¤±')
    plt.title(f'{title} - æŸå¤±æ›²çº¿')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # ç»˜åˆ¶å¯¹æ•°æŸå¤±æ›²çº¿
    plt.subplot(2, 2, 2)
    plt.semilogy(epochs, train_losses, 'b-', label='è®­ç»ƒæŸå¤±', linewidth=2)
    plt.semilogy(epochs, val_losses, 'r-', label='éªŒè¯æŸå¤±', linewidth=2)
    plt.xlabel('Epoch')
    plt.ylabel('æŸå¤± (å¯¹æ•°å°ºåº¦)')
    plt.title('å¯¹æ•°æŸå¤±æ›²çº¿')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # ç»˜åˆ¶æŸå¤±å·®å¼‚
    if len(train_losses) == len(val_losses):
        plt.subplot(2, 2, 3)
        gap = np.array(val_losses) - np.array(train_losses)
        plt.plot(epochs, gap, 'g-', label='éªŒè¯-è®­ç»ƒæŸå¤±å·®', linewidth=2)
        plt.axhline(y=0, color='k', linestyle='--', alpha=0.5)
        plt.xlabel('Epoch')
        plt.ylabel('æŸå¤±å·®å¼‚')
        plt.title('è¿‡æ‹Ÿåˆç›‘æ§')
        plt.legend()
        plt.grid(True, alpha=0.3)
    
    # ç»˜åˆ¶æŸå¤±åˆ†å¸ƒ
    plt.subplot(2, 2, 4)
    plt.hist(train_losses, bins=20, alpha=0.7, label='è®­ç»ƒæŸå¤±', color='blue')
    plt.hist(val_losses, bins=20, alpha=0.7, label='éªŒè¯æŸå¤±', color='red')
    plt.xlabel('æŸå¤±å€¼')
    plt.ylabel('é¢‘æ¬¡')
    plt.title('æŸå¤±åˆ†å¸ƒ')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾è¡¨
    save_file = os.path.join(save_path, 'training_curves.png')
    plt.savefig(save_file, dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"ğŸ“Š è®­ç»ƒæ›²çº¿å·²ä¿å­˜: {save_file}")


def create_sample_grid(
    samples: torch.Tensor,
    save_path: str,
    nrow: int = 4,
    title: str = "ç”Ÿæˆæ ·æœ¬",
    normalize: bool = True,
    value_range: Tuple[float, float] = (-1, 1),
    add_labels: bool = False
) -> None:
    """
    åˆ›å»ºæ ·æœ¬ç½‘æ ¼å›¾
    
    å‚æ•°:
        samples: æ ·æœ¬å¼ é‡ [batch_size, channels, height, width]
        save_path: ä¿å­˜è·¯å¾„
        nrow: æ¯è¡Œæ ·æœ¬æ•°
        title: å›¾è¡¨æ ‡é¢˜
        normalize: æ˜¯å¦å½’ä¸€åŒ–
        value_range: æ•°å€¼èŒƒå›´
        add_labels: æ˜¯å¦æ·»åŠ æ ‡ç­¾
    """
    # åˆ›å»ºç½‘æ ¼
    grid = make_grid(
        samples, 
        nrow=nrow, 
        normalize=normalize, 
        value_range=value_range,
        pad_value=1
    )
    
    # è½¬æ¢ä¸ºnumpyæ•°ç»„
    grid_np = grid.permute(1, 2, 0).cpu().numpy()
    if grid_np.shape[-1] == 1:
        grid_np = grid_np.squeeze(-1)
        cmap = 'gray'
    else:
        cmap = None
    
    # ç»˜åˆ¶å›¾åƒ
    fig, ax = plt.subplots(figsize=(12, 12))
    ax.imshow(grid_np, cmap=cmap)
    ax.set_title(title, fontsize=16, pad=20)
    ax.axis('off')
    
    # æ·»åŠ æ ·æœ¬ç¼–å·
    if add_labels:
        num_samples = samples.shape[0]
        sample_height = samples.shape[2]
        sample_width = samples.shape[3]
        
        for i in range(num_samples):
            row = i // nrow
            col = i % nrow
            x = col * (sample_width + 2) + sample_width // 2
            y = row * (sample_height + 2) + sample_height // 2
            ax.text(x, y, str(i+1), ha='center', va='center',
                   fontsize=12, color='white', weight='bold',
                   bbox=dict(boxstyle='round', facecolor='black', alpha=0.7))
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"ğŸ–¼ï¸  æ ·æœ¬ç½‘æ ¼å·²ä¿å­˜: {save_path}")


def visualize_diffusion_process(
    original_image: torch.Tensor,
    noisy_images: List[torch.Tensor],
    timesteps: List[int],
    save_path: str,
    title: str = "æ‰©æ•£è¿‡ç¨‹å¯è§†åŒ–"
) -> None:
    """
    å¯è§†åŒ–æ‰©æ•£è¿‡ç¨‹
    
    å‚æ•°:
        original_image: åŸå§‹å›¾åƒ [channels, height, width]
        noisy_images: ä¸åŒæ—¶é—´æ­¥çš„å™ªå£°å›¾åƒåˆ—è¡¨
        timesteps: å¯¹åº”çš„æ—¶é—´æ­¥åˆ—è¡¨
        save_path: ä¿å­˜è·¯å¾„
        title: å›¾è¡¨æ ‡é¢˜
    """
    num_steps = len(noisy_images)
    fig, axes = plt.subplots(2, (num_steps + 1) // 2 + 1, figsize=(20, 8))
    axes = axes.flatten()
    
    # æ˜¾ç¤ºåŸå§‹å›¾åƒ
    img = original_image.permute(1, 2, 0).cpu().numpy()
    if img.shape[-1] == 1:
        img = img.squeeze(-1)
        cmap = 'gray'
    else:
        img = (img + 1) / 2  # ä»[-1,1]è½¬æ¢åˆ°[0,1]
        cmap = None
    
    axes[0].imshow(img, cmap=cmap)
    axes[0].set_title('åŸå§‹å›¾åƒ\n(t=0)', fontsize=12)
    axes[0].axis('off')
    
    # æ˜¾ç¤ºå™ªå£°å›¾åƒ
    for i, (noisy_img, t) in enumerate(zip(noisy_images, timesteps)):
        img = noisy_img.permute(1, 2, 0).cpu().numpy()
        if img.shape[-1] == 1:
            img = img.squeeze(-1)
        else:
            img = (img + 1) / 2
        
        axes[i + 1].imshow(img, cmap=cmap)
        axes[i + 1].set_title(f'æ—¶é—´æ­¥ {t}', fontsize=12)
        axes[i + 1].axis('off')
    
    # éšè—å¤šä½™çš„å­å›¾
    for i in range(num_steps + 1, len(axes)):
        axes[i].axis('off')
    
    plt.suptitle(title, fontsize=16)
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"ğŸ”„ æ‰©æ•£è¿‡ç¨‹å¯è§†åŒ–å·²ä¿å­˜: {save_path}")


def visualize_denoising_process(
    initial_noise: torch.Tensor,
    denoised_images: List[torch.Tensor],
    save_path: str,
    title: str = "å»å™ªè¿‡ç¨‹å¯è§†åŒ–",
    show_every: int = 50
) -> None:
    """
    å¯è§†åŒ–å»å™ªè¿‡ç¨‹
    
    å‚æ•°:
        initial_noise: åˆå§‹å™ªå£° [channels, height, width]
        denoised_images: å»å™ªè¿‡ç¨‹ä¸­çš„å›¾åƒåˆ—è¡¨
        save_path: ä¿å­˜è·¯å¾„
        title: å›¾è¡¨æ ‡é¢˜
        show_every: æ˜¾ç¤ºé—´éš”
    """
    # é€‰æ‹©è¦æ˜¾ç¤ºçš„æ—¶é—´æ­¥
    total_steps = len(denoised_images)
    selected_indices = list(range(0, total_steps, show_every))
    if total_steps - 1 not in selected_indices:
        selected_indices.append(total_steps - 1)
    
    num_show = len(selected_indices)
    cols = min(6, num_show)
    rows = (num_show + cols - 1) // cols
    
    fig, axes = plt.subplots(rows, cols, figsize=(3 * cols, 3 * rows))
    if rows == 1:
        axes = axes.reshape(1, -1)
    elif cols == 1:
        axes = axes.reshape(-1, 1)
    
    for idx, step_idx in enumerate(selected_indices):
        row = idx // cols
        col = idx % cols
        
        if step_idx == 0:
            # æ˜¾ç¤ºåˆå§‹å™ªå£°
            img = initial_noise
            step_title = f"åˆå§‹å™ªå£°\n(æ­¥éª¤ {total_steps})"
        else:
            img = denoised_images[step_idx]
            remaining_steps = total_steps - step_idx
            step_title = f"æ­¥éª¤ {remaining_steps}"
        
        # å¤„ç†å›¾åƒ
        img_np = img.permute(1, 2, 0).cpu().numpy()
        if img_np.shape[-1] == 1:
            img_np = img_np.squeeze(-1)
            cmap = 'gray'
        else:
            img_np = torch.clamp((img + 1) / 2, 0, 1).permute(1, 2, 0).cpu().numpy()
            cmap = None
        
        axes[row, col].imshow(img_np, cmap=cmap)
        axes[row, col].set_title(step_title, fontsize=10)
        axes[row, col].axis('off')
    
    # éšè—å¤šä½™çš„å­å›¾
    for idx in range(num_show, rows * cols):
        row = idx // cols
        col = idx % cols
        axes[row, col].axis('off')
    
    plt.suptitle(title, fontsize=16)
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"ğŸ¨ å»å™ªè¿‡ç¨‹å¯è§†åŒ–å·²ä¿å­˜: {save_path}")


def plot_noise_schedule(
    betas: torch.Tensor,
    alphas: torch.Tensor,
    alpha_bars: torch.Tensor,
    save_path: str,
    title: str = "å™ªå£°è°ƒåº¦å¯è§†åŒ–"
) -> None:
    """
    å¯è§†åŒ–å™ªå£°è°ƒåº¦å‚æ•°
    
    å‚æ•°:
        betas: Î²å€¼ [T]
        alphas: Î±å€¼ [T]  
        alpha_bars: Î±Ì…å€¼ [T]
        save_path: ä¿å­˜è·¯å¾„
        title: å›¾è¡¨æ ‡é¢˜
    """
    timesteps = range(len(betas))
    
    fig, axes = plt.subplots(2, 2, figsize=(12, 10))
    
    # Î²å€¼æ›²çº¿
    axes[0, 0].plot(timesteps, betas.cpu().numpy(), 'b-', linewidth=2)
    axes[0, 0].set_title('å™ªå£°è°ƒåº¦ Î²(t)')
    axes[0, 0].set_xlabel('æ—¶é—´æ­¥ t')
    axes[0, 0].set_ylabel('Î²(t)')
    axes[0, 0].grid(True, alpha=0.3)
    
    # Î±å€¼æ›²çº¿
    axes[0, 1].plot(timesteps, alphas.cpu().numpy(), 'r-', linewidth=2)
    axes[0, 1].set_title('Î±(t) = 1 - Î²(t)')
    axes[0, 1].set_xlabel('æ—¶é—´æ­¥ t')
    axes[0, 1].set_ylabel('Î±(t)')
    axes[0, 1].grid(True, alpha=0.3)
    
    # Î±Ì…å€¼æ›²çº¿
    axes[1, 0].plot(timesteps, alpha_bars.cpu().numpy(), 'g-', linewidth=2)
    axes[1, 0].set_title('ç´¯ç§¯å™ªå£° Î±Ì…(t)')
    axes[1, 0].set_xlabel('æ—¶é—´æ­¥ t')
    axes[1, 0].set_ylabel('Î±Ì…(t)')
    axes[1, 0].grid(True, alpha=0.3)
    
    # ä¿¡å™ªæ¯”
    snr = alpha_bars / (1 - alpha_bars)
    axes[1, 1].semilogy(timesteps, snr.cpu().numpy(), 'm-', linewidth=2)
    axes[1, 1].set_title('ä¿¡å™ªæ¯” SNR(t)')
    axes[1, 1].set_xlabel('æ—¶é—´æ­¥ t')
    axes[1, 1].set_ylabel('SNR(t) [å¯¹æ•°å°ºåº¦]')
    axes[1, 1].grid(True, alpha=0.3)
    
    plt.suptitle(title, fontsize=16)
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"ğŸ“ˆ å™ªå£°è°ƒåº¦å¯è§†åŒ–å·²ä¿å­˜: {save_path}")


def plot_attention_maps(
    attention_weights: torch.Tensor,
    input_image: torch.Tensor,
    save_path: str,
    num_heads: int = 8,
    title: str = "æ³¨æ„åŠ›çƒ­å›¾"
) -> None:
    """
    å¯è§†åŒ–æ³¨æ„åŠ›æƒé‡çƒ­å›¾
    
    å‚æ•°:
        attention_weights: æ³¨æ„åŠ›æƒé‡ [batch, heads, seq_len, seq_len]
        input_image: è¾“å…¥å›¾åƒ [batch, channels, height, width]
        save_path: ä¿å­˜è·¯å¾„
        num_heads: æ˜¾ç¤ºçš„æ³¨æ„åŠ›å¤´æ•°
        title: å›¾è¡¨æ ‡é¢˜
    """
    batch_size, num_heads_total, seq_len, _ = attention_weights.shape
    num_heads = min(num_heads, num_heads_total)
    
    # å–ç¬¬ä¸€ä¸ªæ ·æœ¬
    attn = attention_weights[0, :num_heads].cpu().numpy()  # [num_heads, seq_len, seq_len]
    img = input_image[0].cpu().numpy()  # [channels, height, width]
    
    # å¤„ç†è¾“å…¥å›¾åƒ
    if img.shape[0] == 1:
        img = img.squeeze(0)
        img_cmap = 'gray'
    else:
        img = np.transpose(img, (1, 2, 0))
        img = (img + 1) / 2  # ä»[-1,1]è½¬æ¢åˆ°[0,1]
        img_cmap = None
    
    # è®¡ç®—ç½‘æ ¼å°ºå¯¸
    height, width = img.shape[:2]
    grid_size = int(np.sqrt(seq_len))
    
    fig = plt.figure(figsize=(16, 12))
    gs = gridspec.GridSpec(3, num_heads + 1, height_ratios=[1, 1, 1])
    
    # æ˜¾ç¤ºåŸå§‹å›¾åƒ
    ax_img = fig.add_subplot(gs[0, 0])
    ax_img.imshow(img, cmap=img_cmap)
    ax_img.set_title('åŸå§‹å›¾åƒ', fontsize=12)
    ax_img.axis('off')
    
    # æ˜¾ç¤ºæ¯ä¸ªæ³¨æ„åŠ›å¤´çš„å¹³å‡æ³¨æ„åŠ›
    for head in range(num_heads):
        ax = fig.add_subplot(gs[0, head + 1])
        
        # è®¡ç®—å¹³å‡æ³¨æ„åŠ›æƒé‡
        avg_attn = np.mean(attn[head], axis=0)  # [seq_len]
        attn_map = avg_attn.reshape(grid_size, grid_size)
        
        im = ax.imshow(attn_map, cmap='hot', interpolation='bilinear')
        ax.set_title(f'æ³¨æ„åŠ›å¤´ {head + 1}', fontsize=10)
        ax.axis('off')
        plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)
    
    # æ˜¾ç¤ºæ³¨æ„åŠ›æƒé‡çŸ©é˜µ
    for head in range(min(4, num_heads)):
        ax = fig.add_subplot(gs[1 + head // 2, (head % 2) * 2 + 1:(head % 2) * 2 + 3])
        
        im = ax.imshow(attn[head], cmap='Blues', aspect='auto')
        ax.set_title(f'æ³¨æ„åŠ›çŸ©é˜µ - å¤´ {head + 1}', fontsize=10)
        ax.set_xlabel('é”®ä½ç½®')
        ax.set_ylabel('æŸ¥è¯¢ä½ç½®')
        plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)
    
    plt.suptitle(title, fontsize=16)
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"ğŸ” æ³¨æ„åŠ›çƒ­å›¾å·²ä¿å­˜: {save_path}")


def create_comparison_grid(
    real_images: torch.Tensor,
    generated_images: torch.Tensor,
    save_path: str,
    title: str = "çœŸå® vs ç”Ÿæˆå›¾åƒå¯¹æ¯”"
) -> None:
    """
    åˆ›å»ºçœŸå®å›¾åƒä¸ç”Ÿæˆå›¾åƒçš„å¯¹æ¯”ç½‘æ ¼
    
    å‚æ•°:
        real_images: çœŸå®å›¾åƒ [batch_size, channels, height, width]
        generated_images: ç”Ÿæˆå›¾åƒ [batch_size, channels, height, width]
        save_path: ä¿å­˜è·¯å¾„
        title: å›¾è¡¨æ ‡é¢˜
    """
    batch_size = min(real_images.shape[0], generated_images.shape[0])
    
    # åˆ›å»ºäº¤æ›¿æ’åˆ—çš„å›¾åƒ
    comparison_images = []
    for i in range(batch_size):
        comparison_images.append(real_images[i])
        comparison_images.append(generated_images[i])
    
    comparison_tensor = torch.stack(comparison_images)
    
    # åˆ›å»ºç½‘æ ¼
    grid = make_grid(
        comparison_tensor,
        nrow=2,  # æ¯è¡Œ2å¼ å›¾ï¼šçœŸå®ï¼Œç”Ÿæˆ
        normalize=True,
        value_range=(-1, 1),
        pad_value=1
    )
    
    # ç»˜åˆ¶
    grid_np = grid.permute(1, 2, 0).cpu().numpy()
    if grid_np.shape[-1] == 1:
        grid_np = grid_np.squeeze(-1)
        cmap = 'gray'
    else:
        cmap = None
    
    fig, ax = plt.subplots(figsize=(8, batch_size * 2))
    ax.imshow(grid_np, cmap=cmap)
    ax.set_title(title, fontsize=16, pad=20)
    ax.axis('off')
    
    # æ·»åŠ æ ‡ç­¾
    for i in range(batch_size):
        y_pos = i * (real_images.shape[2] + 2) + real_images.shape[2] // 2
        
        # çœŸå®å›¾åƒæ ‡ç­¾
        ax.text(real_images.shape[3] // 2, y_pos, 'çœŸå®', 
               ha='center', va='center', fontsize=12, color='white', weight='bold',
               bbox=dict(boxstyle='round', facecolor='green', alpha=0.7))
        
        # ç”Ÿæˆå›¾åƒæ ‡ç­¾  
        ax.text(real_images.shape[3] + 2 + generated_images.shape[3] // 2, y_pos, 'ç”Ÿæˆ',
               ha='center', va='center', fontsize=12, color='white', weight='bold',
               bbox=dict(boxstyle='round', facecolor='blue', alpha=0.7))
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"ğŸ”„ å¯¹æ¯”ç½‘æ ¼å·²ä¿å­˜: {save_path}")


def create_interpolation_grid(
    start_image: torch.Tensor,
    end_image: torch.Tensor,
    interpolated_images: List[torch.Tensor],
    save_path: str,
    title: str = "å›¾åƒæ’å€¼"
) -> None:
    """
    åˆ›å»ºå›¾åƒæ’å€¼å¯è§†åŒ–
    
    å‚æ•°:
        start_image: èµ·å§‹å›¾åƒ [channels, height, width]
        end_image: ç»“æŸå›¾åƒ [channels, height, width]
        interpolated_images: æ’å€¼å›¾åƒåˆ—è¡¨
        save_path: ä¿å­˜è·¯å¾„
        title: å›¾è¡¨æ ‡é¢˜
    """
    # ç»„åˆæ‰€æœ‰å›¾åƒ
    all_images = [start_image] + interpolated_images + [end_image]
    all_tensor = torch.stack(all_images)
    
    # åˆ›å»ºæ°´å¹³ç½‘æ ¼
    grid = make_grid(
        all_tensor,
        nrow=len(all_images),
        normalize=True,
        value_range=(-1, 1),
        pad_value=1
    )
    
    # ç»˜åˆ¶
    grid_np = grid.permute(1, 2, 0).cpu().numpy()
    if grid_np.shape[-1] == 1:
        grid_np = grid_np.squeeze(-1)
        cmap = 'gray'
    else:
        cmap = None
    
    fig, ax = plt.subplots(figsize=(len(all_images) * 2, 4))
    ax.imshow(grid_np, cmap=cmap)
    ax.set_title(title, fontsize=16, pad=20)
    ax.axis('off')
    
    # æ·»åŠ æ’å€¼æ¯”ä¾‹æ ‡ç­¾
    for i, ratio in enumerate(np.linspace(0, 1, len(all_images))):
        x_pos = i * (start_image.shape[2] + 2) + start_image.shape[2] // 2
        y_pos = start_image.shape[1] + 10
        ax.text(x_pos, y_pos, f'{ratio:.2f}',
               ha='center', va='top', fontsize=10, weight='bold')
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"ğŸŒˆ æ’å€¼ç½‘æ ¼å·²ä¿å­˜: {save_path}")


# æµ‹è¯•å‡½æ•°
def test_visualization():
    """
    æµ‹è¯•å¯è§†åŒ–å‡½æ•°
    """
    print("ğŸ§ª æµ‹è¯•å¯è§†åŒ–å‡½æ•°...")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    train_losses = [2.5, 2.1, 1.8, 1.5, 1.3, 1.1, 0.9, 0.8, 0.7, 0.6]
    val_losses = [2.6, 2.2, 1.9, 1.6, 1.4, 1.2, 1.0, 0.9, 0.8, 0.75]
    
    # æµ‹è¯•è®­ç»ƒæ›²çº¿
    os.makedirs('./test_viz', exist_ok=True)
    plot_training_curves(train_losses, val_losses, './test_viz')
    
    # æµ‹è¯•æ ·æœ¬ç½‘æ ¼
    samples = torch.randn(16, 3, 32, 32)
    create_sample_grid(samples, './test_viz/samples.png')
    
    print("âœ… å¯è§†åŒ–æµ‹è¯•å®Œæˆ!")


if __name__ == "__main__":
    test_visualization()