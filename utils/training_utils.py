#!/usr/bin/env python3
"""
è®­ç»ƒå®ç”¨å·¥å…·å‡½æ•°
==============

è¿™ä¸ªæ¨¡å—æä¾›è®­ç»ƒè¿‡ç¨‹ä¸­çš„å„ç§å®ç”¨å‡½æ•°ï¼š
1. æ—¥å¿—é…ç½®å’Œç®¡ç†
2. æ¨¡å‹æ£€æŸ¥ç‚¹ä¿å­˜å’ŒåŠ è½½
3. è®­ç»ƒçŠ¶æ€ç®¡ç†
4. æ€§èƒ½ç›‘æ§å·¥å…·

ä½œè€…: Diffusionæ•™ç¨‹å›¢é˜Ÿ
æ—¥æœŸ: 2024å¹´
"""

import os
import sys
import torch
import torch.nn as nn
import logging
import json
import pickle
from datetime import datetime
from typing import Dict, Any, Optional, Union
import numpy as np


def setup_logging(log_dir: str, log_level: str = 'INFO') -> None:
    """
    è®¾ç½®æ—¥å¿—é…ç½®
    
    å‚æ•°:
        log_dir: æ—¥å¿—ä¿å­˜ç›®å½•
        log_level: æ—¥å¿—çº§åˆ«
    """
    # åˆ›å»ºæ—¥å¿—ç›®å½•
    os.makedirs(log_dir, exist_ok=True)
    
    # è®¾ç½®æ—¥å¿—æ ¼å¼
    log_format = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    date_format = '%Y-%m-%d %H:%M:%S'
    
    # è·å–æ—¥å¿—çº§åˆ«
    level = getattr(logging, log_level.upper(), logging.INFO)
    
    # é…ç½®æ—¥å¿—
    logging.basicConfig(
        level=level,
        format=log_format,
        datefmt=date_format,
        handlers=[
            # æ§åˆ¶å°è¾“å‡º
            logging.StreamHandler(sys.stdout),
            # æ–‡ä»¶è¾“å‡º
            logging.FileHandler(
                os.path.join(log_dir, f'training_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log'),
                encoding='utf-8'
            )
        ]
    )
    
    # è®¾ç½®ç¬¬ä¸‰æ–¹åº“æ—¥å¿—çº§åˆ«
    logging.getLogger('PIL').setLevel(logging.WARNING)
    logging.getLogger('matplotlib').setLevel(logging.WARNING)
    
    logging.info(f"æ—¥å¿—ç³»ç»Ÿå·²åˆå§‹åŒ–ï¼Œæ—¥å¿—ä¿å­˜è‡³: {log_dir}")


def save_checkpoint(
    filepath: str,
    model: nn.Module,
    optimizer: torch.optim.Optimizer,
    scheduler: Optional[torch.optim.lr_scheduler._LRScheduler] = None,
    epoch: int = 0,
    train_loss: float = 0.0,
    val_loss: float = 0.0,
    extra_info: Dict[str, Any] = None
) -> None:
    """
    ä¿å­˜è®­ç»ƒæ£€æŸ¥ç‚¹
    
    å‚æ•°:
        filepath: ä¿å­˜è·¯å¾„
        model: æ¨¡å‹å¯¹è±¡
        optimizer: ä¼˜åŒ–å™¨
        scheduler: å­¦ä¹ ç‡è°ƒåº¦å™¨
        epoch: å½“å‰epoch
        train_loss: è®­ç»ƒæŸå¤±
        val_loss: éªŒè¯æŸå¤±
        extra_info: é¢å¤–ä¿¡æ¯å­—å…¸
    """
    # å‡†å¤‡æ£€æŸ¥ç‚¹æ•°æ®
    checkpoint = {
        'epoch': epoch,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'train_loss': train_loss,
        'val_loss': val_loss,
        'timestamp': datetime.now().isoformat(),
    }
    
    # æ·»åŠ å­¦ä¹ ç‡è°ƒåº¦å™¨çŠ¶æ€
    if scheduler is not None:
        checkpoint['scheduler_state_dict'] = scheduler.state_dict()
    
    # æ·»åŠ é¢å¤–ä¿¡æ¯
    if extra_info:
        checkpoint.update(extra_info)
    
    # ä¿å­˜æ£€æŸ¥ç‚¹
    try:
        torch.save(checkpoint, filepath)
        logging.info(f"âœ… æ£€æŸ¥ç‚¹å·²ä¿å­˜: {filepath}")
    except Exception as e:
        logging.error(f"âŒ ä¿å­˜æ£€æŸ¥ç‚¹å¤±è´¥: {e}")
        raise


def load_checkpoint(
    filepath: str,
    model: nn.Module,
    optimizer: Optional[torch.optim.Optimizer] = None,
    scheduler: Optional[torch.optim.lr_scheduler._LRScheduler] = None,
    device: Optional[torch.device] = None
) -> Dict[str, Any]:
    """
    åŠ è½½è®­ç»ƒæ£€æŸ¥ç‚¹
    
    å‚æ•°:
        filepath: æ£€æŸ¥ç‚¹æ–‡ä»¶è·¯å¾„
        model: æ¨¡å‹å¯¹è±¡
        optimizer: ä¼˜åŒ–å™¨ï¼ˆå¯é€‰ï¼‰
        scheduler: å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼ˆå¯é€‰ï¼‰
        device: ç›®æ ‡è®¾å¤‡ï¼ˆå¯é€‰ï¼‰
        
    è¿”å›:
        checkpoint: æ£€æŸ¥ç‚¹ä¿¡æ¯å­—å…¸
    """
    if not os.path.exists(filepath):
        raise FileNotFoundError(f"æ£€æŸ¥ç‚¹æ–‡ä»¶ä¸å­˜åœ¨: {filepath}")
    
    try:
        # åŠ è½½æ£€æŸ¥ç‚¹
        if device is not None:
            checkpoint = torch.load(filepath, map_location=device)
        else:
            checkpoint = torch.load(filepath)
        
        # åŠ è½½æ¨¡å‹çŠ¶æ€
        model.load_state_dict(checkpoint['model_state_dict'])
        logging.info(f"âœ… æ¨¡å‹çŠ¶æ€å·²åŠ è½½")
        
        # åŠ è½½ä¼˜åŒ–å™¨çŠ¶æ€
        if optimizer is not None and 'optimizer_state_dict' in checkpoint:
            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
            logging.info(f"âœ… ä¼˜åŒ–å™¨çŠ¶æ€å·²åŠ è½½")
        
        # åŠ è½½å­¦ä¹ ç‡è°ƒåº¦å™¨çŠ¶æ€
        if scheduler is not None and 'scheduler_state_dict' in checkpoint:
            scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
            logging.info(f"âœ… è°ƒåº¦å™¨çŠ¶æ€å·²åŠ è½½")
        
        logging.info(f"âœ… æ£€æŸ¥ç‚¹åŠ è½½å®Œæˆ: {filepath}")
        logging.info(f"   Epoch: {checkpoint.get('epoch', 'Unknown')}")
        logging.info(f"   è®­ç»ƒæŸå¤±: {checkpoint.get('train_loss', 'Unknown')}")
        logging.info(f"   éªŒè¯æŸå¤±: {checkpoint.get('val_loss', 'Unknown')}")
        
        return checkpoint
        
    except Exception as e:
        logging.error(f"âŒ åŠ è½½æ£€æŸ¥ç‚¹å¤±è´¥: {e}")
        raise


def save_model_config(model: nn.Module, save_path: str) -> None:
    """
    ä¿å­˜æ¨¡å‹é…ç½®ä¿¡æ¯
    
    å‚æ•°:
        model: æ¨¡å‹å¯¹è±¡
        save_path: ä¿å­˜è·¯å¾„
    """
    config = {
        'model_class': model.__class__.__name__,
        'model_config': getattr(model, 'config', {}),
        'total_parameters': sum(p.numel() for p in model.parameters()),
        'trainable_parameters': sum(p.numel() for p in model.parameters() if p.requires_grad),
        'model_size_mb': sum(p.numel() for p in model.parameters()) * 4 / 1e6,
        'timestamp': datetime.now().isoformat(),
    }
    
    try:
        with open(save_path, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
        logging.info(f"âœ… æ¨¡å‹é…ç½®å·²ä¿å­˜: {save_path}")
    except Exception as e:
        logging.error(f"âŒ ä¿å­˜æ¨¡å‹é…ç½®å¤±è´¥: {e}")


class TrainingMonitor:
    """
    è®­ç»ƒç›‘æ§å™¨
    
    ç”¨äºè·Ÿè¸ªå’Œè®°å½•è®­ç»ƒè¿‡ç¨‹ä¸­çš„å„ç§æŒ‡æ ‡ã€‚
    """
    
    def __init__(self, save_dir: str):
        """
        åˆå§‹åŒ–è®­ç»ƒç›‘æ§å™¨
        
        å‚æ•°:
            save_dir: ä¿å­˜ç›®å½•
        """
        self.save_dir = save_dir
        self.metrics = {
            'train_losses': [],
            'val_losses': [],
            'learning_rates': [],
            'epochs': [],
            'timestamps': []
        }
        self.best_val_loss = float('inf')
        self.best_epoch = 0
        
        os.makedirs(save_dir, exist_ok=True)
    
    def update(
        self, 
        epoch: int, 
        train_loss: float, 
        val_loss: float, 
        lr: float
    ) -> bool:
        """
        æ›´æ–°è®­ç»ƒæŒ‡æ ‡
        
        å‚æ•°:
            epoch: å½“å‰epoch
            train_loss: è®­ç»ƒæŸå¤±
            val_loss: éªŒè¯æŸå¤±
            lr: å½“å‰å­¦ä¹ ç‡
            
        è¿”å›:
            is_best: æ˜¯å¦æ˜¯æœ€ä½³æ¨¡å‹
        """
        # è®°å½•æŒ‡æ ‡
        self.metrics['epochs'].append(epoch)
        self.metrics['train_losses'].append(train_loss)
        self.metrics['val_losses'].append(val_loss)
        self.metrics['learning_rates'].append(lr)
        self.metrics['timestamps'].append(datetime.now().isoformat())
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯æœ€ä½³æ¨¡å‹
        is_best = val_loss < self.best_val_loss
        if is_best:
            self.best_val_loss = val_loss
            self.best_epoch = epoch
            logging.info(f"ğŸ¯ å‘ç°æ›´å¥½çš„æ¨¡å‹! Epoch {epoch+1}, Val Loss: {val_loss:.4f}")
        
        return is_best
    
    def save_metrics(self) -> None:
        """
        ä¿å­˜è®­ç»ƒæŒ‡æ ‡åˆ°æ–‡ä»¶
        """
        metrics_path = os.path.join(self.save_dir, 'training_metrics.json')
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        summary = {
            'best_epoch': self.best_epoch,
            'best_val_loss': self.best_val_loss,
            'final_train_loss': self.metrics['train_losses'][-1] if self.metrics['train_losses'] else None,
            'final_val_loss': self.metrics['val_losses'][-1] if self.metrics['val_losses'] else None,
            'total_epochs': len(self.metrics['epochs']),
        }
        
        data = {
            'metrics': self.metrics,
            'summary': summary
        }
        
        try:
            with open(metrics_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)
            logging.info(f"âœ… è®­ç»ƒæŒ‡æ ‡å·²ä¿å­˜: {metrics_path}")
        except Exception as e:
            logging.error(f"âŒ ä¿å­˜è®­ç»ƒæŒ‡æ ‡å¤±è´¥: {e}")
    
    def get_summary(self) -> Dict[str, Any]:
        """
        è·å–è®­ç»ƒæ€»ç»“
        
        è¿”å›:
            summary: è®­ç»ƒæ€»ç»“å­—å…¸
        """
        if not self.metrics['epochs']:
            return {'message': 'æš‚æ— è®­ç»ƒæ•°æ®'}
        
        return {
            'æ€»è®­ç»ƒè½®æ•°': len(self.metrics['epochs']),
            'æœ€ä½³éªŒè¯æŸå¤±': f"{self.best_val_loss:.4f}",
            'æœ€ä½³æ¨¡å‹epoch': self.best_epoch + 1,
            'æœ€ç»ˆè®­ç»ƒæŸå¤±': f"{self.metrics['train_losses'][-1]:.4f}",
            'æœ€ç»ˆéªŒè¯æŸå¤±': f"{self.metrics['val_losses'][-1]:.4f}",
            'æœ€ç»ˆå­¦ä¹ ç‡': f"{self.metrics['learning_rates'][-1]:.6f}",
        }


class EarlyStopping:
    """
    æ—©åœæœºåˆ¶
    
    åœ¨éªŒè¯æŸå¤±ä¸å†æ”¹å–„æ—¶æå‰åœæ­¢è®­ç»ƒã€‚
    """
    
    def __init__(self, patience: int = 10, min_delta: float = 0.0, mode: str = 'min'):
        """
        åˆå§‹åŒ–æ—©åœæœºåˆ¶
        
        å‚æ•°:
            patience: å®¹å¿è½®æ•°
            min_delta: æœ€å°æ”¹å–„å¹…åº¦
            mode: ç›‘æ§æ¨¡å¼ ('min' æˆ– 'max')
        """
        self.patience = patience
        self.min_delta = min_delta
        self.mode = mode
        self.counter = 0
        self.best_score = None
        self.early_stop = False
        
        if mode == 'min':
            self.is_better = lambda current, best: current < best - min_delta
        else:
            self.is_better = lambda current, best: current > best + min_delta
    
    def __call__(self, score: float) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦åº”è¯¥æ—©åœ
        
        å‚æ•°:
            score: å½“å‰ç›‘æ§æŒ‡æ ‡å€¼
            
        è¿”å›:
            early_stop: æ˜¯å¦åº”è¯¥æ—©åœ
        """
        if self.best_score is None:
            self.best_score = score
        elif self.is_better(score, self.best_score):
            self.best_score = score
            self.counter = 0
        else:
            self.counter += 1
            if self.counter >= self.patience:
                self.early_stop = True
                logging.info(f"ğŸ›‘ æ—©åœè§¦å‘! å·²è¿ç»­ {self.patience} è½®æ— æ”¹å–„")
        
        return self.early_stop


def count_parameters(model: nn.Module) -> Dict[str, int]:
    """
    ç»Ÿè®¡æ¨¡å‹å‚æ•°æ•°é‡
    
    å‚æ•°:
        model: æ¨¡å‹å¯¹è±¡
        
    è¿”å›:
        param_count: å‚æ•°ç»Ÿè®¡å­—å…¸
    """
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    return {
        'total_parameters': total_params,
        'trainable_parameters': trainable_params,
        'non_trainable_parameters': total_params - trainable_params,
        'model_size_mb': total_params * 4 / 1e6  # å‡è®¾float32
    }


def get_device_info() -> Dict[str, Any]:
    """
    è·å–è®¾å¤‡ä¿¡æ¯
    
    è¿”å›:
        device_info: è®¾å¤‡ä¿¡æ¯å­—å…¸
    """
    info = {
        'platform': sys.platform,
        'python_version': sys.version,
        'pytorch_version': torch.__version__,
    }
    
    if torch.cuda.is_available():
        info.update({
            'cuda_available': True,
            'cuda_version': torch.version.cuda,
            'gpu_count': torch.cuda.device_count(),
            'gpu_names': [torch.cuda.get_device_name(i) for i in range(torch.cuda.device_count())],
            'current_gpu': torch.cuda.current_device(),
            'gpu_memory_gb': torch.cuda.get_device_properties(0).total_memory / 1e9
        })
    else:
        info['cuda_available'] = False
    
    return info


def format_time(seconds: float) -> str:
    """
    æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤º
    
    å‚æ•°:
        seconds: ç§’æ•°
        
    è¿”å›:
        formatted_time: æ ¼å¼åŒ–çš„æ—¶é—´å­—ç¬¦ä¸²
    """
    if seconds < 60:
        return f"{seconds:.1f}ç§’"
    elif seconds < 3600:
        minutes = seconds / 60
        return f"{minutes:.1f}åˆ†é’Ÿ"
    else:
        hours = seconds / 3600
        return f"{hours:.1f}å°æ—¶"


def create_experiment_dir(base_dir: str, experiment_name: str = None) -> str:
    """
    åˆ›å»ºå®éªŒç›®å½•
    
    å‚æ•°:
        base_dir: åŸºç¡€ç›®å½•
        experiment_name: å®éªŒåç§°
        
    è¿”å›:
        experiment_dir: å®éªŒç›®å½•è·¯å¾„
    """
    if experiment_name is None:
        experiment_name = f"exp_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    
    experiment_dir = os.path.join(base_dir, experiment_name)
    
    # åˆ›å»ºç›®å½•ç»“æ„
    subdirs = ['checkpoints', 'logs', 'samples', 'configs']
    for subdir in subdirs:
        os.makedirs(os.path.join(experiment_dir, subdir), exist_ok=True)
    
    logging.info(f"ğŸ“ å®éªŒç›®å½•å·²åˆ›å»º: {experiment_dir}")
    return experiment_dir


# æµ‹è¯•å‡½æ•°
def test_training_utils():
    """
    æµ‹è¯•è®­ç»ƒå·¥å…·å‡½æ•°
    """
    print("ğŸ§ª æµ‹è¯•è®­ç»ƒå·¥å…·å‡½æ•°...")
    
    # æµ‹è¯•è®¾å¤‡ä¿¡æ¯
    device_info = get_device_info()
    print(f"âœ… è®¾å¤‡ä¿¡æ¯: {device_info}")
    
    # æµ‹è¯•æ—¶é—´æ ¼å¼åŒ–
    print(f"âœ… æ—¶é—´æ ¼å¼åŒ–: {format_time(3661)}")
    
    # æµ‹è¯•è®­ç»ƒç›‘æ§å™¨
    monitor = TrainingMonitor('./test_monitor')
    monitor.update(0, 1.5, 1.2, 0.001)
    monitor.update(1, 1.3, 1.1, 0.0009)
    summary = monitor.get_summary()
    print(f"âœ… è®­ç»ƒç›‘æ§å™¨: {summary}")
    
    print("âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡!")


if __name__ == "__main__":
    test_training_utils()