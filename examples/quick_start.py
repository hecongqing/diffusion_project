#!/usr/bin/env python3
"""
Diffusionæ¨¡å‹å¿«é€Ÿå…¥é—¨ç¤ºä¾‹
=========================

è¿™ä¸ªè„šæœ¬æ¼”ç¤ºäº†å¦‚ä½•ä½¿ç”¨diffusersåº“å¿«é€Ÿç”Ÿæˆå›¾åƒã€‚
é€‚åˆåˆå­¦è€…å¿«é€Ÿä½“éªŒæ‰©æ•£æ¨¡å‹çš„åŸºæœ¬åŠŸèƒ½ã€‚

ä½œè€…: Diffusionæ•™ç¨‹å›¢é˜Ÿ
æ—¥æœŸ: 2024å¹´
"""

import torch
import matplotlib.pyplot as plt
from PIL import Image
from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler
import os
import warnings
warnings.filterwarnings('ignore')

def setup_device():
    """
    é…ç½®è®¡ç®—è®¾å¤‡
    
    è¿”å›:
        device: å¯ç”¨çš„è®¡ç®—è®¾å¤‡ (cuda/mps/cpu)
    """
    if torch.cuda.is_available():
        device = "cuda"
        print(f"âœ… ä½¿ç”¨GPU: {torch.cuda.get_device_name()}")
        print(f"   æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
    elif torch.backends.mps.is_available():  # Apple Silicon
        device = "mps"
        print("âœ… ä½¿ç”¨Apple Silicon GPU")
    else:
        device = "cpu"
        print("âš ï¸  ä½¿ç”¨CPU (é€Ÿåº¦è¾ƒæ…¢)")
    
    return device

def load_model(device):
    """
    åŠ è½½é¢„è®­ç»ƒçš„Stable Diffusionæ¨¡å‹
    
    å‚æ•°:
        device: è®¡ç®—è®¾å¤‡
    
    è¿”å›:
        pipeline: é…ç½®å¥½çš„æ‰©æ•£æ¨¡å‹ç®¡é“
    """
    print("ğŸ”„ æ­£åœ¨åŠ è½½Stable Diffusionæ¨¡å‹...")
    
    # ä½¿ç”¨Hugging Faceä¸Šçš„é¢„è®­ç»ƒæ¨¡å‹
    model_id = "runwayml/stable-diffusion-v1-5"
    
    try:
        # åˆ›å»ºç®¡é“
        pipeline = StableDiffusionPipeline.from_pretrained(
            model_id,
            torch_dtype=torch.float16 if device == "cuda" else torch.float32,
            safety_checker=None,  # ä¸ºäº†æ¼”ç¤ºç®€å•èµ·è§ï¼Œç¦ç”¨å®‰å…¨æ£€æŸ¥
            requires_safety_checker=False
        )
        
        # ä½¿ç”¨æ›´å¿«çš„è°ƒåº¦å™¨
        pipeline.scheduler = DPMSolverMultistepScheduler.from_config(
            pipeline.scheduler.config
        )
        
        # ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡
        pipeline = pipeline.to(device)
        
        # å¦‚æœä½¿ç”¨GPUï¼Œå¯ç”¨å†…å­˜ä¼˜åŒ–
        if device == "cuda":
            pipeline.enable_attention_slicing()  # èŠ‚çœæ˜¾å­˜
            pipeline.enable_xformers_memory_efficient_attention()  # åŠ é€Ÿæ³¨æ„åŠ›è®¡ç®—
        
        print("âœ… æ¨¡å‹åŠ è½½å®Œæˆ!")
        return pipeline
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        print("ğŸ’¡ å°è¯•ä½¿ç”¨CPUæˆ–æ£€æŸ¥ç½‘ç»œè¿æ¥")
        return None

def generate_image(pipeline, prompt, negative_prompt="", steps=20, guidance_scale=7.5):
    """
    ç”Ÿæˆå›¾åƒ
    
    å‚æ•°:
        pipeline: æ‰©æ•£æ¨¡å‹ç®¡é“
        prompt: æ­£å‘æç¤ºè¯ (æè¿°æƒ³è¦ç”Ÿæˆçš„å†…å®¹)
        negative_prompt: è´Ÿå‘æç¤ºè¯ (æè¿°ä¸æƒ³è¦çš„å†…å®¹)
        steps: æ¨ç†æ­¥æ•° (æ›´å¤šæ­¥æ•° = æ›´é«˜è´¨é‡, ä½†æ›´æ…¢)
        guidance_scale: å¼•å¯¼å¼ºåº¦ (æ›´é«˜ = æ›´è´´è¿‘æç¤ºè¯)
    
    è¿”å›:
        image: ç”Ÿæˆçš„PILå›¾åƒ
    """
    print(f"ğŸ¨ æ­£åœ¨ç”Ÿæˆå›¾åƒ...")
    print(f"   æç¤ºè¯: {prompt}")
    print(f"   æ¨ç†æ­¥æ•°: {steps}")
    print(f"   å¼•å¯¼å¼ºåº¦: {guidance_scale}")
    
    # è®¾ç½®éšæœºç§å­ä»¥ä¾¿ç»“æœå¯å¤ç°
    generator = torch.Generator(device=pipeline.device).manual_seed(42)
    
    try:
        # ç”Ÿæˆå›¾åƒ
        with torch.autocast(pipeline.device.type):
            result = pipeline(
                prompt=prompt,
                negative_prompt=negative_prompt,
                num_inference_steps=steps,
                guidance_scale=guidance_scale,
                generator=generator,
                height=512,
                width=512
            )
        
        image = result.images[0]
        print("âœ… å›¾åƒç”Ÿæˆå®Œæˆ!")
        return image
        
    except Exception as e:
        print(f"âŒ å›¾åƒç”Ÿæˆå¤±è´¥: {e}")
        return None

def save_and_display_image(image, prompt, output_dir="outputs"):
    """
    ä¿å­˜å¹¶æ˜¾ç¤ºç”Ÿæˆçš„å›¾åƒ
    
    å‚æ•°:
        image: PILå›¾åƒ
        prompt: ç”¨äºç”Ÿæˆçš„æç¤ºè¯
        output_dir: è¾“å‡ºç›®å½•
    """
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    
    # ç”Ÿæˆå®‰å…¨çš„æ–‡ä»¶å
    safe_prompt = "".join(c for c in prompt if c.isalnum() or c in (' ', '-', '_')).rstrip()
    safe_prompt = safe_prompt[:50]  # é™åˆ¶é•¿åº¦
    filename = f"{safe_prompt}.png"
    filepath = os.path.join(output_dir, filename)
    
    # ä¿å­˜å›¾åƒ
    image.save(filepath)
    print(f"ğŸ’¾ å›¾åƒå·²ä¿å­˜åˆ°: {filepath}")
    
    # æ˜¾ç¤ºå›¾åƒ
    plt.figure(figsize=(8, 8))
    plt.imshow(image)
    plt.title(f"ç”Ÿæˆçš„å›¾åƒ\næç¤ºè¯: {prompt}", fontsize=12, pad=20)
    plt.axis('off')
    plt.tight_layout()
    plt.show()

def demo_basic_generation():
    """
    åŸºç¡€å›¾åƒç”Ÿæˆæ¼”ç¤º
    """
    print("=" * 60)
    print("ğŸš€ Diffusionæ¨¡å‹å¿«é€Ÿå…¥é—¨æ¼”ç¤º")
    print("=" * 60)
    
    # 1. è®¾ç½®è®¾å¤‡
    device = setup_device()
    
    # 2. åŠ è½½æ¨¡å‹
    pipeline = load_model(device)
    if pipeline is None:
        return
    
    # 3. å®šä¹‰ç¤ºä¾‹æç¤ºè¯
    demo_prompts = [
        {
            "prompt": "a beautiful landscape with mountains and lake, sunset, highly detailed",
            "negative_prompt": "ugly, blurry, low quality",
            "description": "ç¾ä¸½çš„å±±æ¹–é£æ™¯"
        },
        {
            "prompt": "a cute cat wearing a wizard hat, magical, fantasy art",
            "negative_prompt": "scary, dark, low quality",
            "description": "æˆ´å·«å¸ˆå¸½çš„å¯çˆ±çŒ«å’ª"
        },
        {
            "prompt": "a futuristic city with flying cars, cyberpunk style, neon lights",
            "negative_prompt": "old, ancient, low quality",
            "description": "èµ›åšæœ‹å…‹æœªæ¥åŸå¸‚"
        }
    ]
    
    # 4. ç”Ÿæˆå›¾åƒ
    print(f"\nğŸ“ å°†ç”Ÿæˆ {len(demo_prompts)} å¼ ç¤ºä¾‹å›¾åƒ:")
    for i, prompt_config in enumerate(demo_prompts, 1):
        print(f"\n--- ç¤ºä¾‹ {i}/{len(demo_prompts)}: {prompt_config['description']} ---")
        
        image = generate_image(
            pipeline=pipeline,
            prompt=prompt_config["prompt"],
            negative_prompt=prompt_config["negative_prompt"],
            steps=20,
            guidance_scale=7.5
        )
        
        if image:
            save_and_display_image(
                image, 
                f"{i}_{prompt_config['description']}"
            )

def demo_parameter_comparison():
    """
    å‚æ•°å¯¹æ¯”æ¼”ç¤º - å±•ç¤ºä¸åŒå‚æ•°å¯¹ç”Ÿæˆç»“æœçš„å½±å“
    """
    print("\n" + "=" * 60)
    print("ğŸ”¬ å‚æ•°å¯¹æ¯”æ¼”ç¤º")
    print("=" * 60)
    
    device = setup_device()
    pipeline = load_model(device)
    if pipeline is None:
        return
    
    base_prompt = "a serene garden with blooming flowers"
    
    # å¯¹æ¯”ä¸åŒçš„å¼•å¯¼å¼ºåº¦
    guidance_scales = [5.0, 7.5, 15.0]
    
    print(f"\nğŸ“Š å¯¹æ¯”ä¸åŒå¼•å¯¼å¼ºåº¦çš„æ•ˆæœ:")
    print(f"æç¤ºè¯: {base_prompt}")
    
    for guidance in guidance_scales:
        print(f"\nğŸ›ï¸  å¼•å¯¼å¼ºåº¦: {guidance}")
        
        image = generate_image(
            pipeline=pipeline,
            prompt=base_prompt,
            steps=20,
            guidance_scale=guidance
        )
        
        if image:
            save_and_display_image(
                image, 
                f"guidance_{guidance}_{base_prompt[:20]}"
            )

def interactive_generation():
    """
    äº¤äº’å¼å›¾åƒç”Ÿæˆ
    """
    print("\n" + "=" * 60)
    print("ğŸ® äº¤äº’å¼å›¾åƒç”Ÿæˆ")
    print("=" * 60)
    
    device = setup_device()
    pipeline = load_model(device)
    if pipeline is None:
        return
    
    print("\nğŸ’¡ ç°åœ¨æ‚¨å¯ä»¥è¾“å…¥è‡ªå·±çš„æç¤ºè¯æ¥ç”Ÿæˆå›¾åƒ!")
    print("æç¤º: ä½¿ç”¨è‹±æ–‡æè¿°ï¼Œè¶Šè¯¦ç»†è¶Šå¥½")
    print("è¾“å…¥ 'quit' é€€å‡º\n")
    
    while True:
        try:
            # è·å–ç”¨æˆ·è¾“å…¥
            user_prompt = input("ğŸ¨ è¯·è¾“å…¥æç¤ºè¯: ").strip()
            
            if user_prompt.lower() in ['quit', 'exit', 'é€€å‡º']:
                print("ğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨!")
                break
            
            if not user_prompt:
                print("âŒ æç¤ºè¯ä¸èƒ½ä¸ºç©ºï¼Œè¯·é‡æ–°è¾“å…¥")
                continue
            
            # å¯é€‰çš„è´Ÿå‘æç¤ºè¯
            negative_prompt = input("ğŸš« è´Ÿå‘æç¤ºè¯ (å¯é€‰ï¼Œç›´æ¥å›è½¦è·³è¿‡): ").strip()
            
            # ç”Ÿæˆå›¾åƒ
            image = generate_image(
                pipeline=pipeline,
                prompt=user_prompt,
                negative_prompt=negative_prompt,
                steps=20,
                guidance_scale=7.5
            )
            
            if image:
                save_and_display_image(image, user_prompt)
                
                # è¯¢é—®æ˜¯å¦ç»§ç»­
                continue_choice = input("\nğŸ”„ æ˜¯å¦ç»§ç»­ç”Ÿæˆ? (y/n): ").strip().lower()
                if continue_choice not in ['y', 'yes', 'æ˜¯']:
                    print("ğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨!")
                    break
                    
        except KeyboardInterrupt:
            print("\nğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨!")
            break
        except Exception as e:
            print(f"âŒ å‘ç”Ÿé”™è¯¯: {e}")
            continue

def main():
    """
    ä¸»å‡½æ•° - å±•ç¤ºä¸åŒçš„æ¼”ç¤ºæ¨¡å¼
    """
    print("ğŸ¯ Diffusionæ¨¡å‹å¿«é€Ÿå…¥é—¨")
    print("é€‰æ‹©æ¼”ç¤ºæ¨¡å¼:")
    print("1. åŸºç¡€å›¾åƒç”Ÿæˆæ¼”ç¤º")
    print("2. å‚æ•°å¯¹æ¯”æ¼”ç¤º") 
    print("3. äº¤äº’å¼ç”Ÿæˆ")
    print("4. å…¨éƒ¨è¿è¡Œ")
    
    try:
        choice = input("\nè¯·é€‰æ‹© (1-4): ").strip()
        
        if choice == "1":
            demo_basic_generation()
        elif choice == "2":
            demo_parameter_comparison()
        elif choice == "3":
            interactive_generation()
        elif choice == "4":
            demo_basic_generation()
            demo_parameter_comparison()
            interactive_generation()
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¿è¡ŒåŸºç¡€æ¼”ç¤º")
            demo_basic_generation()
            
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"âŒ ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
    
    print("\nğŸ‰ æ¼”ç¤ºå®Œæˆ! æ›´å¤šæ•™ç¨‹è¯·æŸ¥çœ‹é¡¹ç›®æ–‡æ¡£ã€‚")

if __name__ == "__main__":
    main()