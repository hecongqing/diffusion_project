#!/usr/bin/env python3
"""
DDPMæ¨¡å‹è®­ç»ƒè„šæœ¬
==============

è¿™ä¸ªè„šæœ¬æä¾›äº†å®Œæ•´çš„DDPMè®­ç»ƒæµç¨‹ï¼ŒåŒ…æ‹¬ï¼š
1. æ•°æ®åŠ è½½å’Œé¢„å¤„ç†
2. æ¨¡å‹åˆå§‹åŒ–å’Œé…ç½®
3. è®­ç»ƒå¾ªç¯å’ŒéªŒè¯
4. æ¨¡å‹ä¿å­˜å’ŒåŠ è½½
5. è®­ç»ƒè¿›åº¦å¯è§†åŒ–

ä½œè€…: Diffusionæ•™ç¨‹å›¢é˜Ÿ
æ—¥æœŸ: 2024å¹´
"""

import os
import sys
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader
from torchvision import transforms, datasets
from torchvision.utils import save_image, make_grid
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm
import argparse
import logging
from datetime import datetime
import json
import wandb
from typing import Dict, List, Optional, Tuple

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from models.ddpm.ddpm_model import DDPM, NoiseScheduler
from models.unet.unet_architecture import UNet
from utils.training_utils import setup_logging, save_checkpoint, load_checkpoint
from utils.visualization import plot_training_curves, create_sample_grid

def parse_args():
    """
    è§£æå‘½ä»¤è¡Œå‚æ•°
    """
    parser = argparse.ArgumentParser(description='DDPMæ¨¡å‹è®­ç»ƒ')
    
    # æ•°æ®ç›¸å…³å‚æ•°
    parser.add_argument('--dataset', type=str, default='cifar10', 
                       choices=['cifar10', 'celeba', 'mnist', 'custom'],
                       help='è®­ç»ƒæ•°æ®é›†')
    parser.add_argument('--data_path', type=str, default='./data',
                       help='æ•°æ®é›†è·¯å¾„')
    parser.add_argument('--image_size', type=int, default=32,
                       help='å›¾åƒå°ºå¯¸')
    parser.add_argument('--batch_size', type=int, default=64,
                       help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--num_workers', type=int, default=4,
                       help='æ•°æ®åŠ è½½è¿›ç¨‹æ•°')
    
    # æ¨¡å‹ç›¸å…³å‚æ•°  
    parser.add_argument('--model_channels', type=int, nargs='+', 
                       default=[128, 256, 512, 512],
                       help='UNetå„å±‚é€šé“æ•°')
    parser.add_argument('--attention_levels', type=int, nargs='+',
                       default=[0, 0, 1, 1],
                       help='å„å±‚æ˜¯å¦ä½¿ç”¨æ³¨æ„åŠ› (0/1)')
    parser.add_argument('--num_layers', type=int, default=2,
                       help='æ¯ä¸ªå—çš„æ®‹å·®å±‚æ•°')
    parser.add_argument('--time_emb_dim', type=int, default=512,
                       help='æ—¶é—´åµŒå…¥ç»´åº¦')
    
    # æ‰©æ•£è¿‡ç¨‹å‚æ•°
    parser.add_argument('--num_timesteps', type=int, default=1000,
                       help='æ‰©æ•£æ­¥æ•°')
    parser.add_argument('--beta_start', type=float, default=0.0001,
                       help='å™ªå£°è°ƒåº¦èµ·å§‹å€¼')
    parser.add_argument('--beta_end', type=float, default=0.02,
                       help='å™ªå£°è°ƒåº¦ç»“æŸå€¼')
    parser.add_argument('--schedule', type=str, default='linear',
                       choices=['linear', 'cosine'],
                       help='å™ªå£°è°ƒåº¦ç­–ç•¥')
    
    # è®­ç»ƒç›¸å…³å‚æ•°
    parser.add_argument('--epochs', type=int, default=100,
                       help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--lr', type=float, default=2e-4,
                       help='å­¦ä¹ ç‡')
    parser.add_argument('--weight_decay', type=float, default=0.0,
                       help='æƒé‡è¡°å‡')
    parser.add_argument('--grad_clip', type=float, default=1.0,
                       help='æ¢¯åº¦è£å‰ªé˜ˆå€¼')
    
    # ä¿å­˜å’Œæ—¥å¿—å‚æ•°
    parser.add_argument('--save_dir', type=str, default='./checkpoints',
                       help='æ¨¡å‹ä¿å­˜ç›®å½•')
    parser.add_argument('--log_dir', type=str, default='./logs',
                       help='æ—¥å¿—ä¿å­˜ç›®å½•')
    parser.add_argument('--save_interval', type=int, default=10,
                       help='æ¨¡å‹ä¿å­˜é—´éš”(è½®æ•°)')
    parser.add_argument('--sample_interval', type=int, default=5,
                       help='ç”Ÿæˆæ ·æœ¬é—´éš”(è½®æ•°)')
    parser.add_argument('--log_interval', type=int, default=100,
                       help='æ—¥å¿—è®°å½•é—´éš”(æ­¥æ•°)')
    
    # è®¾å¤‡å’Œå…¶ä»–å‚æ•°
    parser.add_argument('--device', type=str, default='auto',
                       help='è®¡ç®—è®¾å¤‡ (auto/cuda/cpu)')
    parser.add_argument('--mixed_precision', action='store_true',
                       help='æ˜¯å¦ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ')
    parser.add_argument('--use_wandb', action='store_true',
                       help='æ˜¯å¦ä½¿ç”¨Weights & Biasesè®°å½•')
    parser.add_argument('--wandb_project', type=str, default='ddpm-training',
                       help='WandBé¡¹ç›®åç§°')
    parser.add_argument('--resume', type=str, default=None,
                       help='æ¢å¤è®­ç»ƒçš„æ£€æŸ¥ç‚¹è·¯å¾„')
    parser.add_argument('--seed', type=int, default=42,
                       help='éšæœºç§å­')
    
    return parser.parse_args()


def setup_device(device_arg: str) -> torch.device:
    """
    è®¾ç½®è®¡ç®—è®¾å¤‡
    
    å‚æ•°:
        device_arg: è®¾å¤‡å‚æ•°
        
    è¿”å›:
        device: PyTorchè®¾å¤‡å¯¹è±¡
    """
    if device_arg == 'auto':
        if torch.cuda.is_available():
            device = torch.device('cuda')
            print(f"ğŸš€ ä½¿ç”¨GPU: {torch.cuda.get_device_name()}")
            print(f"   æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
        elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
            device = torch.device('mps')
            print("ğŸš€ ä½¿ç”¨Apple Silicon GPU")
        else:
            device = torch.device('cpu')
            print("âš ï¸  ä½¿ç”¨CPUè®­ç»ƒï¼ˆé€Ÿåº¦è¾ƒæ…¢ï¼‰")
    else:
        device = torch.device(device_arg)
        print(f"ğŸš€ ä½¿ç”¨æŒ‡å®šè®¾å¤‡: {device}")
    
    return device


def create_datasets(args) -> Tuple[DataLoader, DataLoader]:
    """
    åˆ›å»ºè®­ç»ƒå’ŒéªŒè¯æ•°æ®é›†
    
    å‚æ•°:
        args: å‘½ä»¤è¡Œå‚æ•°
        
    è¿”å›:
        train_loader: è®­ç»ƒæ•°æ®åŠ è½½å™¨
        val_loader: éªŒè¯æ•°æ®åŠ è½½å™¨
    """
    # æ•°æ®é¢„å¤„ç†
    if args.dataset == 'cifar10':
        # CIFAR-10æ•°æ®é›†é¢„å¤„ç†
        transform = transforms.Compose([
            transforms.Resize(args.image_size),
            transforms.RandomHorizontalFlip(p=0.5),  # æ•°æ®å¢å¼º
            transforms.ToTensor(),
            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # å½’ä¸€åŒ–åˆ°[-1, 1]
        ])
        
        # åŠ è½½æ•°æ®é›†
        train_dataset = datasets.CIFAR10(
            root=args.data_path,
            train=True,
            download=True,
            transform=transform
        )
        
        val_dataset = datasets.CIFAR10(
            root=args.data_path,
            train=False,
            download=True,
            transform=transforms.Compose([
                transforms.Resize(args.image_size),
                transforms.ToTensor(),
                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
            ])
        )
        
    elif args.dataset == 'mnist':
        # MNISTæ•°æ®é›†é¢„å¤„ç†
        transform = transforms.Compose([
            transforms.Resize(args.image_size),
            transforms.ToTensor(),
            transforms.Normalize((0.5,), (0.5,))  # å½’ä¸€åŒ–åˆ°[-1, 1]
        ])
        
        train_dataset = datasets.MNIST(
            root=args.data_path,
            train=True,
            download=True,
            transform=transform
        )
        
        val_dataset = datasets.MNIST(
            root=args.data_path,
            train=False,
            download=True,
            transform=transform
        )
        
    elif args.dataset == 'celeba':
        # CelebAæ•°æ®é›†é¢„å¤„ç†
        transform = transforms.Compose([
            transforms.CenterCrop(140),
            transforms.Resize(args.image_size),
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.ToTensor(),
            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
        ])
        
        # æ³¨æ„ï¼šCelebAéœ€è¦æ‰‹åŠ¨ä¸‹è½½
        train_dataset = datasets.CelebA(
            root=args.data_path,
            split='train',
            download=False,  # æ‰‹åŠ¨ä¸‹è½½
            transform=transform
        )
        
        val_dataset = datasets.CelebA(
            root=args.data_path,
            split='valid',
            download=False,
            transform=transforms.Compose([
                transforms.CenterCrop(140),
                transforms.Resize(args.image_size),
                transforms.ToTensor(),
                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
            ])
        )
        
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®é›†: {args.dataset}")
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(
        train_dataset,
        batch_size=args.batch_size,
        shuffle=True,
        num_workers=args.num_workers,
        pin_memory=True,
        drop_last=True
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=args.batch_size,
        shuffle=False,
        num_workers=args.num_workers,
        pin_memory=True
    )
    
    print(f"ğŸ“Š æ•°æ®é›†ä¿¡æ¯:")
    print(f"   è®­ç»ƒé›†: {len(train_dataset)} å¼ å›¾åƒ")
    print(f"   éªŒè¯é›†: {len(val_dataset)} å¼ å›¾åƒ")
    print(f"   æ‰¹æ¬¡å¤§å°: {args.batch_size}")
    print(f"   è®­ç»ƒæ‰¹æ¬¡æ•°: {len(train_loader)}")
    
    return train_loader, val_loader


def create_model(args, device: torch.device) -> DDPM:
    """
    åˆ›å»ºDDPMæ¨¡å‹
    
    å‚æ•°:
        args: å‘½ä»¤è¡Œå‚æ•°
        device: è®¡ç®—è®¾å¤‡
        
    è¿”å›:
        model: DDPMæ¨¡å‹
    """
    # ç¡®å®šè¾“å…¥é€šé“æ•°
    if args.dataset == 'mnist':
        in_channels = 1
    else:
        in_channels = 3
    
    # è½¬æ¢æ³¨æ„åŠ›çº§åˆ«å‚æ•°
    attention_levels = [bool(x) for x in args.attention_levels]
    
    # åˆ›å»ºUNetç½‘ç»œ
    unet = UNet(
        in_channels=in_channels,
        out_channels=in_channels,
        channels=args.model_channels,
        num_layers=args.num_layers,
        attention_levels=attention_levels,
        time_emb_dim=args.time_emb_dim
    )
    
    # åˆ›å»ºå™ªå£°è°ƒåº¦å™¨
    noise_scheduler = NoiseScheduler(
        num_timesteps=args.num_timesteps,
        beta_start=args.beta_start,
        beta_end=args.beta_end,
        schedule=args.schedule
    )
    
    # åˆ›å»ºDDPMæ¨¡å‹
    model = DDPM(unet, noise_scheduler)
    model.to(device)
    
    # æ‰“å°æ¨¡å‹ä¿¡æ¯
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    print(f"ğŸ—ï¸  æ¨¡å‹ä¿¡æ¯:")
    print(f"   æ€»å‚æ•°é‡: {total_params:,}")
    print(f"   å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
    print(f"   æ¨¡å‹å¤§å°: {total_params * 4 / 1e6:.1f} MB")
    
    return model


def train_epoch(
    model: DDPM,
    train_loader: DataLoader,
    optimizer: torch.optim.Optimizer,
    device: torch.device,
    epoch: int,
    args,
    scaler: Optional[torch.cuda.amp.GradScaler] = None
) -> Dict[str, float]:
    """
    è®­ç»ƒä¸€ä¸ªepoch
    
    å‚æ•°:
        model: DDPMæ¨¡å‹
        train_loader: è®­ç»ƒæ•°æ®åŠ è½½å™¨
        optimizer: ä¼˜åŒ–å™¨
        device: è®¡ç®—è®¾å¤‡
        epoch: å½“å‰epoch
        args: å‘½ä»¤è¡Œå‚æ•°
        scaler: æ··åˆç²¾åº¦ç¼©æ”¾å™¨
        
    è¿”å›:
        metrics: è®­ç»ƒæŒ‡æ ‡å­—å…¸
    """
    model.train()
    total_loss = 0.0
    num_batches = len(train_loader)
    
    # åˆ›å»ºè¿›åº¦æ¡
    pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{args.epochs}')
    
    for batch_idx, (images, _) in enumerate(pbar):
        images = images.to(device)
        
        # æ¸…é›¶æ¢¯åº¦
        optimizer.zero_grad()
        
        if args.mixed_precision and scaler is not None:
            # æ··åˆç²¾åº¦è®­ç»ƒ
            with torch.cuda.amp.autocast():
                loss = model.compute_loss(images)
            
            scaler.scale(loss).backward()
            
            # æ¢¯åº¦è£å‰ª
            if args.grad_clip > 0:
                scaler.unscale_(optimizer)
                torch.nn.utils.clip_grad_norm_(model.parameters(), args.grad_clip)
            
            scaler.step(optimizer)
            scaler.update()
        else:
            # æ™®é€šè®­ç»ƒ
            loss = model.compute_loss(images)
            loss.backward()
            
            # æ¢¯åº¦è£å‰ª
            if args.grad_clip > 0:
                torch.nn.utils.clip_grad_norm_(model.parameters(), args.grad_clip)
            
            optimizer.step()
        
        # ç´¯è®¡æŸå¤±
        total_loss += loss.item()
        avg_loss = total_loss / (batch_idx + 1)
        
        # æ›´æ–°è¿›åº¦æ¡
        pbar.set_postfix({
            'Loss': f'{loss.item():.4f}',
            'Avg Loss': f'{avg_loss:.4f}'
        })
        
        # è®°å½•æ—¥å¿—
        if (batch_idx + 1) % args.log_interval == 0:
            step = epoch * num_batches + batch_idx + 1
            
            if args.use_wandb:
                wandb.log({
                    'train/loss': loss.item(),
                    'train/avg_loss': avg_loss,
                    'train/step': step,
                    'train/epoch': epoch + 1
                })
    
    return {
        'loss': total_loss / num_batches,
        'num_batches': num_batches
    }


def validate_model(
    model: DDPM,
    val_loader: DataLoader,
    device: torch.device,
    epoch: int,
    args
) -> Dict[str, float]:
    """
    éªŒè¯æ¨¡å‹æ€§èƒ½
    
    å‚æ•°:
        model: DDPMæ¨¡å‹
        val_loader: éªŒè¯æ•°æ®åŠ è½½å™¨
        device: è®¡ç®—è®¾å¤‡
        epoch: å½“å‰epoch
        args: å‘½ä»¤è¡Œå‚æ•°
        
    è¿”å›:
        metrics: éªŒè¯æŒ‡æ ‡å­—å…¸
    """
    model.eval()
    total_loss = 0.0
    num_batches = 0
    
    with torch.no_grad():
        for images, _ in tqdm(val_loader, desc='Validation'):
            images = images.to(device)
            
            if args.mixed_precision:
                with torch.cuda.amp.autocast():
                    loss = model.compute_loss(images)
            else:
                loss = model.compute_loss(images)
            
            total_loss += loss.item()
            num_batches += 1
    
    avg_loss = total_loss / num_batches
    
    print(f"ğŸ“Š éªŒè¯ç»“æœ - Epoch {epoch+1}: Loss = {avg_loss:.4f}")
    
    return {
        'loss': avg_loss,
        'num_batches': num_batches
    }


def generate_samples(
    model: DDPM,
    device: torch.device,
    num_samples: int = 16,
    image_size: int = 32,
    channels: int = 3
) -> torch.Tensor:
    """
    ç”Ÿæˆæ ·æœ¬å›¾åƒ
    
    å‚æ•°:
        model: DDPMæ¨¡å‹
        device: è®¡ç®—è®¾å¤‡
        num_samples: ç”Ÿæˆæ ·æœ¬æ•°é‡
        image_size: å›¾åƒå°ºå¯¸
        channels: å›¾åƒé€šé“æ•°
        
    è¿”å›:
        samples: ç”Ÿæˆçš„æ ·æœ¬
    """
    model.eval()
    
    with torch.no_grad():
        # ä»éšæœºå™ªå£°å¼€å§‹
        samples = torch.randn(num_samples, channels, image_size, image_size, device=device)
        
        # é€æ­¥å»å™ª
        samples = model.sample(samples, show_progress=True)
        
        # é™åˆ¶åˆ°[-1, 1]èŒƒå›´
        samples = torch.clamp(samples, -1, 1)
    
    return samples


def main():
    """
    ä¸»è®­ç»ƒå‡½æ•°
    """
    # è§£æå‚æ•°
    args = parse_args()
    
    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(args.seed)
    np.random.seed(args.seed)
    
    # åˆ›å»ºä¿å­˜ç›®å½•
    os.makedirs(args.save_dir, exist_ok=True)
    os.makedirs(args.log_dir, exist_ok=True)
    os.makedirs(os.path.join(args.save_dir, 'samples'), exist_ok=True)
    
    # è®¾ç½®æ—¥å¿—
    setup_logging(args.log_dir)
    logging.info(f"å¼€å§‹DDPMè®­ç»ƒ - {datetime.now()}")
    logging.info(f"å‚æ•°: {vars(args)}")
    
    # åˆå§‹åŒ–WandB
    if args.use_wandb:
        wandb.init(
            project=args.wandb_project,
            config=vars(args),
            name=f"ddpm_{args.dataset}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        )
    
    # è®¾ç½®è®¾å¤‡
    device = setup_device(args.device)
    
    # åˆ›å»ºæ•°æ®é›†
    train_loader, val_loader = create_datasets(args)
    
    # åˆ›å»ºæ¨¡å‹
    model = create_model(args, device)
    
    # åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = torch.optim.AdamW(
        model.parameters(),
        lr=args.lr,
        weight_decay=args.weight_decay
    )
    
    # å­¦ä¹ ç‡è°ƒåº¦å™¨
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
        optimizer, T_max=args.epochs, eta_min=args.lr * 0.1
    )
    
    # æ··åˆç²¾åº¦è®­ç»ƒ
    scaler = torch.cuda.amp.GradScaler() if args.mixed_precision else None
    
    # æ¢å¤è®­ç»ƒï¼ˆå¦‚æœæŒ‡å®šï¼‰
    start_epoch = 0
    if args.resume:
        checkpoint = load_checkpoint(args.resume, model, optimizer, scheduler)
        start_epoch = checkpoint['epoch'] + 1
        print(f"âœ… ä»epoch {start_epoch}æ¢å¤è®­ç»ƒ")
    
    # è®­ç»ƒå†å²
    train_losses = []
    val_losses = []
    
    # ç¡®å®šå›¾åƒé€šé“æ•°
    channels = 1 if args.dataset == 'mnist' else 3
    
    print("ğŸš€ å¼€å§‹è®­ç»ƒ...")
    
    # è®­ç»ƒå¾ªç¯
    for epoch in range(start_epoch, args.epochs):
        print(f"\n{'='*50}")
        print(f"Epoch {epoch+1}/{args.epochs}")
        print(f"{'='*50}")
        
        # è®­ç»ƒä¸€ä¸ªepoch
        train_metrics = train_epoch(
            model, train_loader, optimizer, device, epoch, args, scaler
        )
        train_losses.append(train_metrics['loss'])
        
        # éªŒè¯æ¨¡å‹
        val_metrics = validate_model(model, val_loader, device, epoch, args)
        val_losses.append(val_metrics['loss'])
        
        # æ›´æ–°å­¦ä¹ ç‡
        scheduler.step()
        current_lr = scheduler.get_last_lr()[0]
        
        # è®°å½•åˆ°WandB
        if args.use_wandb:
            wandb.log({
                'epoch': epoch + 1,
                'train/epoch_loss': train_metrics['loss'],
                'val/epoch_loss': val_metrics['loss'],
                'lr': current_lr
            })
        
        # æ‰“å°epochæ€»ç»“
        print(f"\nğŸ“ˆ Epoch {epoch+1} æ€»ç»“:")
        print(f"   è®­ç»ƒæŸå¤±: {train_metrics['loss']:.4f}")
        print(f"   éªŒè¯æŸå¤±: {val_metrics['loss']:.4f}")
        print(f"   å­¦ä¹ ç‡: {current_lr:.6f}")
        
        # ç”Ÿæˆæ ·æœ¬
        if (epoch + 1) % args.sample_interval == 0:
            print("ğŸ¨ ç”Ÿæˆæ ·æœ¬å›¾åƒ...")
            samples = generate_samples(
                model, device, num_samples=16, 
                image_size=args.image_size, channels=channels
            )
            
            # ä¿å­˜æ ·æœ¬
            sample_path = os.path.join(
                args.save_dir, 'samples', f'epoch_{epoch+1:03d}.png'
            )
            save_image(
                samples, sample_path,
                nrow=4, normalize=True, value_range=(-1, 1)
            )
            
            if args.use_wandb:
                wandb.log({
                    f'samples/epoch_{epoch+1}': wandb.Image(sample_path)
                })
        
        # ä¿å­˜æ£€æŸ¥ç‚¹
        if (epoch + 1) % args.save_interval == 0:
            checkpoint_path = os.path.join(
                args.save_dir, f'checkpoint_epoch_{epoch+1:03d}.pth'
            )
            save_checkpoint(
                checkpoint_path, model, optimizer, scheduler, 
                epoch, train_metrics['loss'], val_metrics['loss']
            )
            print(f"ğŸ’¾ å·²ä¿å­˜æ£€æŸ¥ç‚¹: {checkpoint_path}")
    
    # ä¿å­˜æœ€ç»ˆæ¨¡å‹
    final_model_path = os.path.join(args.save_dir, 'final_model.pth')
    save_checkpoint(
        final_model_path, model, optimizer, scheduler,
        args.epochs - 1, train_losses[-1], val_losses[-1]
    )
    print(f"ğŸ¯ è®­ç»ƒå®Œæˆï¼æœ€ç»ˆæ¨¡å‹ä¿å­˜è‡³: {final_model_path}")
    
    # ç»˜åˆ¶è®­ç»ƒæ›²çº¿
    plot_training_curves(train_losses, val_losses, args.save_dir)
    
    # å…³é—­WandB
    if args.use_wandb:
        wandb.finish()
    
    logging.info(f"è®­ç»ƒå®Œæˆ - {datetime.now()}")


if __name__ == '__main__':
    main()